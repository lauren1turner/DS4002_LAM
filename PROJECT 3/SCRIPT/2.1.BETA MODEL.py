# -*- coding: utf-8 -*-
"""Colorizing_attempt_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qfEOTwo44ILALaIWMZ6DdMCOgAdFPuoJ
"""

# Why LAB?  The L channel is brightness alone, and the a/b channels capture color.
!pip install scikit-image

import os
import glob
import numpy as np
import cv2
from skimage.color import rgb2lab, lab2rgb
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.layers import Conv2D, UpSampling2D, Input, BatchNormalization, Activation
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

# Choose a manageable size for all images
IMG_HEIGHT = 256
IMG_WIDTH  = 256

def load_image(path):
    """Read an image from disk, convert to RGB and resize."""
    img = cv2.imread(path)                 # BGR by default
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))
    return img

def preprocess(img):
    """
    Convert RGB to LAB, normalize:
      - L channel to [0,1]
      - a/b channels to [-1,1]
    """
    lab = rgb2lab(img).astype('float32')
    L  = lab[..., 0] / 100.0               # 0→100 → 0→1
    ab = lab[..., 1:] / 128.0              # approximately -128→127 → -1→1
    return L[..., np.newaxis], ab

# 3. Load your dataset (match every file with "jpj" in its name)
import glob
from sklearn.model_selection import train_test_split

# 3.1—Grab every file under /content/ whose filename contains "jpj"
#      If your files are really .jpj (not a typo), this will catch them.
#      If they’re actually .jpg, you might want: glob.glob('/content/*.jpg')
paths = glob.glob('/content/*jpg*')

# 3.2—Preallocate lists for L and ab channels
L_list, ab_list = [], []

for p in paths:
    # 3.2.1—Read, convert BGR→RGB, and resize
    img = load_image(p)         # uses your helper: cv2 → RGB → fixed size

    # 3.2.2—Convert to LAB and normalize each channel
    L, ab = preprocess(img)     # splits into L∈[0,1] and ab∈[-1,1]

    # 3.2.3—Accumulate
    L_list.append(L)
    ab_list.append(ab)

# 3.3—Stack into numpy arrays of shape (N, H, W, C)
L_array  = np.stack(L_list, axis=0)   # → (num_images, H, W, 1)
ab_array = np.stack(ab_list, axis=0)  # → (num_images, H, W, 2)

# 3.4—Split into train/test so we can both learn and evaluate generalization
X_train, X_test, Y_train, Y_test = train_test_split(
    L_array, ab_array,
    test_size=0.2,
    random_state=42
)

print(f"Found {len(paths)} total images; "
      f"Training on {X_train.shape[0]}, testing on {X_test.shape[0]}")

# 4. Build (or re‑build) the colorizer model
#    This encoder‑decoder architecture compresses the grayscale input
#    then learns to upsample back to full resolution in the ab channels.

from tensorflow.keras.layers import Conv2D, UpSampling2D, Input, BatchNormalization, Activation
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

def build_colorizer_model():
    inp = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 1), name='L_input')

    # --- Encoder: downsample and extract features ---
    x = Conv2D(64, (3,3), strides=2, padding='same')(inp)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)

    x = Conv2D(128, (3,3), strides=2, padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)

    x = Conv2D(256, (3,3), strides=2, padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)

    # --- Decoder: upsample back to (H,W) and predict 2 color channels ---
    x = UpSampling2D((2,2))(x)
    x = Conv2D(128, (3,3), padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)

    x = UpSampling2D((2,2))(x)
    x = Conv2D(64, (3,3), padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)

    x = UpSampling2D((2,2))(x)
    # tanh activation keeps outputs in [-1,1], matching our normalized ab range
    out = Conv2D(2, (3,3), padding='same', activation='tanh', name='ab_output')(x)

    return Model(inputs=inp, outputs=out)

model = build_colorizer_model()
model.compile(optimizer=Adam(1e-4), loss='mse')  # MSE on ab channels
model.summary()

# 5. Train the model
#    With only ~84 images, overfitting is a real risk—monitor train vs val loss.

EPOCHS     = 100
BATCH_SIZE = 8

history = model.fit(
    X_train, Y_train,
    validation_data=(X_test, Y_test),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE
)

# 6. Colorize & visualize on held‑out test images

def display_colorization(L_gray, ab_pred):
    # 6.1—Denormalize channels back to LAB ranges
    L  = L_gray * 100.0
    ab = ab_pred * 128.0

    # 6.2—Reconstruct LAB image
    lab = np.zeros((IMG_HEIGHT, IMG_WIDTH, 3), dtype='float32')
    lab[..., 0]  = L[..., 0]
    lab[..., 1:] = ab

    # 6.3—Convert to RGB and clip
    rgb = np.clip(lab2rgb(lab), 0, 1)

    # 6.4—Plot side‑by‑side
    plt.figure(figsize=(8,4))
    plt.subplot(1,2,1)
    plt.imshow(L_gray.squeeze(), cmap='gray')
    plt.title('Input (L)')
    plt.axis('off')

    plt.subplot(1,2,2)
    plt.imshow(rgb)
    plt.title('Predicted color')
    plt.axis('off')
    plt.show()

# Sample a few test cases at random
for idx in np.random.choice(len(X_test), 3, replace=False):
    L_in   = X_test[idx:idx+1]
    ab_out = model.predict(L_in)
    display_colorization(L_in[0], ab_out[0])

import os
import numpy as np
import matplotlib.pyplot as plt
from skimage.color import lab2rgb

def display_colorization(L_gray, ab_pred, save_path=None):
    """
    Displays the L→RGB colorization side‑by‑side, and if save_path is provided,
    also writes the figure out to that file.

    Args:
        L_gray    (np.ndarray): Single‑channel input, normalized to [0,1].
        ab_pred   (np.ndarray): Predicted a/b channels, normalized to [-1,1].
        save_path (str, optional): Path (including filename) to save the PNG.
    """
    # 6.1—Denormalize channels back to LAB ranges
    # L was scaled to [0,1]; multiply to get [0,100]
    L  = L_gray * 100.0
    # a/b were scaled to [-1,1]; multiply to get [-128,128]
    ab = ab_pred * 128.0

    # 6.2—Reconstruct LAB image
    lab = np.zeros((IMG_HEIGHT, IMG_WIDTH, 3), dtype='float32')
    lab[..., 0]  = L[..., 0]
    lab[..., 1:] = ab

    # 6.3—Convert to RGB and clip values to [0,1]
    rgb = np.clip(lab2rgb(lab), 0, 1)

    # 6.4—Create the matplotlib figure
    fig = plt.figure(figsize=(8, 4))
    ax1 = fig.add_subplot(1, 2, 1)
    ax1.imshow(L_gray.squeeze(), cmap='gray')
    ax1.set_title('Input (L)')
    ax1.axis('off')

    ax2 = fig.add_subplot(1, 2, 2)
    ax2.imshow(rgb)
    ax2.set_title('Predicted color')
    ax2.axis('off')

    # 6.5—Save to disk if desired
    if save_path:
        # Ensure directory exists so save doesn't error
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        # Save the current figure. bbox_inches='tight' trims whitespace.
        fig.savefig(save_path, bbox_inches='tight', dpi=150)

    # 6.6—Show in‐notebook
    plt.show()
    # 6.7—Close to free memory
    plt.close(fig)

# Usage: sample a few and save them
output_dir = 'colorized_results'
for idx in np.random.choice(len(X_test), 3, replace=False):
    L_in   = X_test[idx:idx+1]         # grab one L-channel
    ab_out = model.predict(L_in)      # predict a/b channels

    # build a filename for each example
    fname = f'colorized_{idx:03d}.png'
    save_path = os.path.join(output_dir, fname)

    # call our updated function with save_path
    display_colorization(L_in[0], ab_out[0], save_path=save_path)

    print(f"→ saved: {save_path}")

from tensorflow.keras.models import load_model

# --- After training your model ---
# `model` is your trained Keras Model instance.

# 1.1—Save the full model (architecture, weights, compile‐info)
model.save('my_colorizer_model.h5')
# └─ Saves:
#     • model topology (layers, config)
#     • learned weights
#     • optimizer state (so you can .fit() further if desired)

# --- Later, in a fresh script/session ---
# 1.2—Reload it exactly as it was
model = load_model('my_colorizer_model.h5')
# └─ You can now call model.predict(), model.evaluate(), or even
#    resume training with model.fit() without redefining its code.

# — After training your model —
# Save in Keras v3 “.keras” format (architecture + weights + compile state)
model.save('my_colorizer_model.keras')

# …later, in a fresh session…
from tensorflow.keras.models import load_model

# This should now load without any “mse” lookup errors:
model = load_model('my_colorizer_model.keras')
